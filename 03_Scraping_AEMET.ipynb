{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scraping. Obtención de predicción de radiación desde AEMET"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para el modelo de producción, se obtendrán los datos proporcionados por la AEMET referentes a la radiación global diaria. Estos datos, son suministrados directamente desde la API de la plataforma OpenData de la agencia, facilitando su manipulación.\n",
    "\n",
    "Lo que buscamos con ello, es recojer e introducir los parámetros de entrada diarios de radiación que luego serán introducidos en el modelo entrenado, permitiendonos predecir la producción eléctrica que tendremos a lo largo del día.\n",
    "\n",
    "Éste script solo se ejecutará una vez al día, ya que luego los datos serán almacenados en un archivo CSV."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tras registrarnos en la plataforma, se nos suministra una \"api_key\" que nos permite solicitar los datos deseados a la misma, descargandose estos en formato de texto plano."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "api_key = \"eyJhbGciOiJIUzI1NiJ9.eyJzdWIiOiJhYmhfbWFzcGFAaG90bWFpbC5jb20iLCJqdGkiOiIxNjU4M2UxYS02YjhmLTQwMjctYTU4YS02YmQ2ZjVhM2U3MGMiLCJpc3MiOiJBRU1FVCIsImlhdCI6MTU3NzE4NDI0MiwidXNlcklkIjoiMTY1ODNlMWEtNmI4Zi00MDI3LWE1OGEtNmJkNmY1YTNlNzBjIiwicm9sZSI6IiJ9.Ov09paQ1cXsLACg_FKe3qdFpUyI-yAuXhu74rUmpD-w\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nos conectamos mediante la lbreria \"request\" a la plataforma, y descargamos los datos del servidor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Url de los datos que deseamos obtener, que son los pertenecientes a la red especial de radiación.\n",
    "\n",
    "url = \"https://opendata.aemet.es/opendata/api/red/especial/radiacion/\"\n",
    "\n",
    "querystring = {\"api_key\":api_key}\n",
    "\n",
    "headers = {'cache-control': \"no-cache\"}\n",
    "\n",
    "# Tras la solicitud, obtenemos un json con la url donde están publicados los datos a descargar. La url\n",
    "# se encuentra en el campo dato.\n",
    "\n",
    "response = requests.request(\"GET\", url, headers=headers, params=querystring)\n",
    "\n",
    "# Descargamos los datos desde la url suministrada.\n",
    "\n",
    "url_data = requests.request(\"GET\", eval(response.text)[\"datos\"], headers=headers, params=querystring).text\n",
    "\n",
    "# Todos los datos, se encuentran entrecomillados, por ello pasamos a eliminarlas.\n",
    "url_data = url_data.replace('\"', '') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tratamos los datos suministrados, transformandolos de texto plano a un dataframe, que luego será guardado en un archivo CSV, el cuál nos valdrá de entrada tanto para el modelo como para la visualización de los mismos en el Dashboard."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>City</th>\n",
       "      <th>Station</th>\n",
       "      <th>Hour</th>\n",
       "      <th>Global_Radiation</th>\n",
       "      <th>Diffuse_Radiation</th>\n",
       "      <th>Ultraviolet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>Barcelona</td>\n",
       "      <td>0201D</td>\n",
       "      <td>12</td>\n",
       "      <td>131</td>\n",
       "      <td>49</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>Lleida</td>\n",
       "      <td>9771C</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>Almería Aeropuerto</td>\n",
       "      <td>6325O</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>215</th>\n",
       "      <td>Lleida</td>\n",
       "      <td>9771C</td>\n",
       "      <td>15</td>\n",
       "      <td>17</td>\n",
       "      <td>7</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>457</th>\n",
       "      <td>Toledo</td>\n",
       "      <td>3260B</td>\n",
       "      <td>16</td>\n",
       "      <td>45</td>\n",
       "      <td>49</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   City Station Hour Global_Radiation Diffuse_Radiation  \\\n",
       "74            Barcelona   0201D   12              131                49   \n",
       "197              Lleida   9771C    6                0                 0   \n",
       "60   Almería Aeropuerto   6325O   20                0                 0   \n",
       "215              Lleida   9771C   15               17                 7   \n",
       "457              Toledo   3260B   16               45                49   \n",
       "\n",
       "    Ultraviolet  \n",
       "74            3  \n",
       "197              \n",
       "60           56  \n",
       "215              \n",
       "457              "
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Separamos la información por líneas.\n",
    "\n",
    "url_data = url_data.splitlines()\n",
    "\n",
    "# Guardamos la fecha del día predicción, que se encuentra en el segundo elemento de la lista.\n",
    "\n",
    "date = url_data[1]\n",
    "\n",
    "# Obtenemos las horas de predicción que se nos ha suministrado. Normalmente oscilan entre las 5-20 horas.\n",
    "\n",
    "str_hour = url_data[2].split(';').index('Tipo')\n",
    "end_hour = url_data[2].split(';').index('SUMA')\n",
    "\n",
    "hours = url_data[2].split(';')[str_hour+1:end_hour]\n",
    "\n",
    "# Creamos la cabecera de nuestro dataframe.\n",
    "\n",
    "station_df = pd.DataFrame(columns =['City', 'Station', 'Hour', 'Global_Radiation', \n",
    "                                   'Diffuse_Radiation', 'Ultraviolet'])\n",
    "\n",
    "# Recorremos las líneas de los datos, desde las 3 hasta el final. Las dos primeras son la cabecera que\n",
    "# solo aportan la fecha y el nombre del archivo.\n",
    "\n",
    "for station_data in url_data[3:]:\n",
    "    \n",
    "    station_data = station_data.split(';') # Separamos la información por ;\n",
    "    \n",
    "    city = station_data[0]    # Guardamos el nombre de la ciudad\n",
    "    station = station_data[1] # Guardamos la fecha de los datos\n",
    "    \n",
    "    indx_GL = station_data.index('GL') + 1  # Guardamos los indices donde comienzan los datos de GL\n",
    "    indx_DF = station_data.index('DF') + 1  # Guardamos los indices donde comienzan los datos de DF\n",
    "    indx_UV = station_data.index('UVB') + 2 # Guardamos los indices donde comienzan los datos de UVB\n",
    "    \n",
    "    # Recorremos la lista de los elementos, y guardamos los datos en un dataframe. El formato siempre será el\n",
    "    # el mismo: Ciudad, estación, hora, dato de GL, dato de DF, dato UV. De esta manera guardamos todos los datos\n",
    "    # en un mismo Dataframe.\n",
    "    \n",
    "    for i in range(len(hours)):\n",
    "        \n",
    "        station_df.loc[i+len(station_df)] = [city, station, hours[i], station_data[i+indx_GL], \n",
    "                                             station_data[i+indx_DF], station_data[i+indx_UV]]\n",
    "\n",
    "station_df.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Procedemos a guardar el Data Frame en un archivo CSV, que podremos utilizar posteriormente con mayor facilidad para la visualización y predicción de la producción."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Guardamos el archivo en local\n",
    "station_df.to_csv('/home/dsc/Documents/TFM-Sun-Power-Prediction/dataset_aemet/'+ date + '.csv', \n",
    "                  sep=';', index=False)\n",
    "\n",
    "# Guardamos el nombre del archivo para subirlo a Drive\n",
    "file_name = '/home/dsc/Documents/TFM-Sun-Power-Prediction/dataset_aemet/'+ date + '.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cargarmos los modelos entrenados y les pasamos los datos de radiación descargados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cargamos los modelos ya entrenados para volverlos a utilizar. Tras descargar y tratar los datos de la AEMET, procederemos a pasarlos por el modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "regDG_VDC = pickle.load(open(\"regDG_VDC.pickle\", \"rb\"))\n",
    "regDG_CDC = pickle.load(open(\"regDG_CDC.pickle\", \"rb\"))\n",
    "regDG_PDC = pickle.load(open(\"regDG_PDC.pickle\", \"rb\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ejecutamos la predicción de los datos mediante el modelo. Pero antes, recabamos los datos del CSV ya guardado y, tras cambiar el tipo de datos de String a float32, realizamos una interpolación para eliminar los NaN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "aemet_data = pd.read_csv(file_name,sep=';') # Recuperamos el archivo CSV anteriormente guardado.\n",
    "\n",
    "aemet_data[['Global_Radiation', 'Diffuse_Radiation',\n",
    "       'Ultraviolet']].astype(\"float32\") # Transformamos los datos a tipo float32\n",
    "\n",
    "aemet_data.interpolate(inplace=True) # Interpolamos para eliminar los datos NaN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Realizamos la predicción de los valores de radiación, en función de los valores de entrada. Es muy probable que muchos de los valores estén a 0 por motivos desconocidos, por lo que la predicción no tendrá el acierto esperado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "aemet_data['Predict_VDC']= pd.DataFrame(regDG_VDC.predict(aemet_data[['Global_Radiation', \n",
    "                                                                      'Diffuse_Radiation','Ultraviolet']]))\n",
    "\n",
    "aemet_data['Predict_CDC']= pd.DataFrame(regDG_CDC.predict(aemet_data[['Global_Radiation', \n",
    "                                                                      'Diffuse_Radiation','Ultraviolet']]))\n",
    "\n",
    "aemet_data['Predict_PDC']= pd.DataFrame(regDG_PDC.predict(aemet_data[['Global_Radiation', \n",
    "                                                                      'Diffuse_Radiation', 'Ultraviolet']]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>City</th>\n",
       "      <th>Station</th>\n",
       "      <th>Hour</th>\n",
       "      <th>Global_Radiation</th>\n",
       "      <th>Diffuse_Radiation</th>\n",
       "      <th>Ultraviolet</th>\n",
       "      <th>Predict_VDC</th>\n",
       "      <th>Predict_CDC</th>\n",
       "      <th>Predict_PDC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <td>Córdoba Aeropuerto</td>\n",
       "      <td>5402</td>\n",
       "      <td>11</td>\n",
       "      <td>153.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>28.073208</td>\n",
       "      <td>6.484268</td>\n",
       "      <td>179.360197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>453</th>\n",
       "      <td>Tortosa</td>\n",
       "      <td>9981A</td>\n",
       "      <td>8</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>28.870553</td>\n",
       "      <td>6.484268</td>\n",
       "      <td>179.360197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>388</th>\n",
       "      <td>Santander</td>\n",
       "      <td>1111</td>\n",
       "      <td>18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>53.000000</td>\n",
       "      <td>23.773683</td>\n",
       "      <td>0.980087</td>\n",
       "      <td>20.080182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>401</th>\n",
       "      <td>Soria</td>\n",
       "      <td>2030</td>\n",
       "      <td>16</td>\n",
       "      <td>29.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>28.870553</td>\n",
       "      <td>6.484268</td>\n",
       "      <td>179.360197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155</th>\n",
       "      <td>Huelva</td>\n",
       "      <td>4642E</td>\n",
       "      <td>10</td>\n",
       "      <td>79.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>31.500000</td>\n",
       "      <td>28.073208</td>\n",
       "      <td>6.484268</td>\n",
       "      <td>179.360197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>Barcelona</td>\n",
       "      <td>0201D</td>\n",
       "      <td>12</td>\n",
       "      <td>131.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>28.073208</td>\n",
       "      <td>6.484268</td>\n",
       "      <td>179.360197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>209</th>\n",
       "      <td>Lleida</td>\n",
       "      <td>9771C</td>\n",
       "      <td>19</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>23.086957</td>\n",
       "      <td>23.773683</td>\n",
       "      <td>0.980087</td>\n",
       "      <td>20.080182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>Cádiz</td>\n",
       "      <td>5973</td>\n",
       "      <td>7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>24.849432</td>\n",
       "      <td>0.335481</td>\n",
       "      <td>9.224765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>288</th>\n",
       "      <td>Murcia</td>\n",
       "      <td>7178I</td>\n",
       "      <td>8</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>28.870553</td>\n",
       "      <td>6.484268</td>\n",
       "      <td>179.360197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249</th>\n",
       "      <td>Málaga</td>\n",
       "      <td>6156</td>\n",
       "      <td>14</td>\n",
       "      <td>90.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>28.073208</td>\n",
       "      <td>6.484268</td>\n",
       "      <td>179.360197</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   City Station  Hour  Global_Radiation  Diffuse_Radiation  \\\n",
       "126  Córdoba Aeropuerto    5402    11             153.0               33.0   \n",
       "453             Tortosa   9981A     8               5.0                4.0   \n",
       "388           Santander    1111    18               0.0                0.0   \n",
       "401               Soria    2030    16              29.0               27.0   \n",
       "155              Huelva   4642E    10              79.0               33.0   \n",
       "67            Barcelona   0201D    12             131.0               49.0   \n",
       "209              Lleida   9771C    19               0.0                0.0   \n",
       "92                Cádiz    5973     7               0.0                0.0   \n",
       "288              Murcia   7178I     8               2.0                2.0   \n",
       "249              Málaga    6156    14              90.0               65.0   \n",
       "\n",
       "     Ultraviolet  Predict_VDC  Predict_CDC  Predict_PDC  \n",
       "126     2.000000    28.073208     6.484268   179.360197  \n",
       "453     0.000000    28.870553     6.484268   179.360197  \n",
       "388    53.000000    23.773683     0.980087    20.080182  \n",
       "401     0.000000    28.870553     6.484268   179.360197  \n",
       "155    31.500000    28.073208     6.484268   179.360197  \n",
       "67      3.000000    28.073208     6.484268   179.360197  \n",
       "209    23.086957    23.773683     0.980087    20.080182  \n",
       "92      0.000000    24.849432     0.335481     9.224765  \n",
       "288     0.000000    28.870553     6.484268   179.360197  \n",
       "249    12.000000    28.073208     6.484268   179.360197  "
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aemet_data.sample(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Subir archivos a google drive"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Subiremos los archivos a Google Drive para poder trabajar con ellos desde el Dashboard implementado en Tableau, el cual corre sobre un PC."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your browser has been opened to visit:\n",
      "\n",
      "    https://accounts.google.com/o/oauth2/auth?client_id=93417544293-1s6ei4pnt9f84qua81cv8g062vsgpuof.apps.googleusercontent.com&redirect_uri=http%3A%2F%2Flocalhost%3A8080%2F&scope=https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive&access_type=offline&response_type=code\n",
      "\n",
      "Authentication successful.\n"
     ]
    }
   ],
   "source": [
    "# Importamos las librerias\n",
    "\n",
    "from pydrive.auth import GoogleAuth\n",
    "from pydrive.drive import GoogleDrive\n",
    "import os\n",
    "\n",
    "# Nos autentificamos en Google Drive y creamos la conección.\n",
    "g_login = GoogleAuth()\n",
    "g_login.LocalWebserverAuth()\n",
    "drive = GoogleDrive(g_login)\n",
    "g_login.LocalWebserverAuth()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Abrimos el archivo que queremos subir, y lo subimos a la ubicacion de la carpeta compartida mediante ID\n",
    "with open(file_name,\"r\") as file:\n",
    "    \n",
    "    file_drive = drive.CreateFile({'title':os.path.basename(file.name), \n",
    "                                   \"parents\": [{\"kind\": \"drive#fileLink\", \n",
    "                                                \"id\": \"1-hoNgYsZW1h4gYKY9uAPrJfEAaTOhGCW\"}]})  \n",
    "    file_drive.SetContentString(file.read()) \n",
    "    file_drive.Upload() "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
